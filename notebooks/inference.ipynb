{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def print_gpu_memory(prefix=\"\"):\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / (1024 ** 2)\n",
    "        reserved = torch.cuda.memory_reserved() / (1024 ** 2)\n",
    "        print(f\"{prefix} Memory Allocated: {allocated:.2f} MB\")\n",
    "        print(f\"{prefix} Memory Reserved: {reserved:.2f} MB\")\n",
    "    else:\n",
    "        print(\"CUDA is not available.\")\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache() \n",
    "\n",
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import src.data.preprocess_data as data\n",
    "import src.training.train_model as train\n",
    "import src.data.view as view\n",
    "import src.models.unets as unets\n",
    "import src.models.hrnets as hrnets\n",
    "import src.training.post_processing as post\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'UNetSmall-256-type-CE-diceW.pth'\n",
    "model_name = 'UNetSmall-256-type-crf-CEW.pth'\n",
    "#model_name = 'UNet-256-type-CE.pth'\n",
    "#model_name = 'UNetConvNext-224-type-CEW.pth'\n",
    "#model_name = 'HRNetW32-512-type-CEW.pth'\n",
    "patch_size = int(model_name.split('-')[1])\n",
    "weighted = 'W.pth' in model_name\n",
    "if model_name.split('-')[2]=='type':\n",
    "    num_classes = 5\n",
    "if model_name.split('-')[2]=='binary':\n",
    "    num_classes = 2\n",
    "loss_mode = model_name.split('-')[-1].split('.')[0]\n",
    "if loss_mode.endswith('W'):\n",
    "    loss_mode = loss_mode[:-1]\n",
    "print(loss_mode)\n",
    "crf=False\n",
    "dist=False\n",
    "if model_name.split('-')[3]=='crf':\n",
    "    crf = True\n",
    "if model_name.split('-')[3]=='dist':\n",
    "    dist = True\n",
    "\n",
    "criterion = train.CombinedLoss(loss_mode = loss_mode, weights = None, return_all_losses=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "working_dir = os.path.abspath('..')\n",
    "ckp_file = os.path.join(working_dir, 'models', model_name)\n",
    "\n",
    "print('Model name:', model_name)\n",
    "if model_name.startswith('UNetSmall-'):\n",
    "    model = unets.UNetSmall(in_channels=12, out_channels=num_classes, crf=crf, use_dist=dist).to(device) \n",
    "if model_name.startswith('UNet-'):\n",
    "    model = unets.UNet(in_channels=12, out_channels=num_classes).to(device) \n",
    "elif model_name.startswith('UNetResNet34-'):\n",
    "    model = unets.UNetResNet34(in_channels=12, out_channels=num_classes).to(device) \n",
    "elif model_name.startswith('UNetEfficientNetB0-'):\n",
    "    model = unets.UNetEfficientNetB0(in_channels=12, out_channels=num_classes).to(device) \n",
    "elif model_name.startswith('UNetConvNext-'):\n",
    "    model = unets.UNetConvNext(in_channels=12, out_channels=num_classes).to(device) \n",
    "elif model_name.startswith('HRNetW18'):\n",
    "    model = hrnets.HRNetSegmentation(in_channels= 12, num_classes=num_classes, backbone=\"hrnet_w18_small\", pretrained=True,).to(device)\n",
    "elif model_name.startswith('HRNetW32'):\n",
    "    model = hrnets.HRNetSegmentation(in_channels= 12, num_classes=num_classes, backbone=\"hrnet_w32\", pretrained=True,).to(device)\n",
    "elif model_name.startswith('HRNetW48'):\n",
    "    model = hrnets.HRNetSegmentation(in_channels= 12, num_classes=num_classes, backbone=\"hrnet_w48\", pretrained=True,).to(device)\n",
    "checkpoint = torch.load(ckp_file, weights_only=False)\n",
    "        \n",
    "start_epoch = checkpoint['epoch'] + 1\n",
    "best_epoch = checkpoint['best_epoch']\n",
    "model.load_state_dict(checkpoint['best_model_state_dict'])\n",
    "#optimizer.load_state_dict(checkpoint['best_optimizer_state_dict']) \n",
    "best_val_loss = checkpoint['best_val_loss']\n",
    "best_epoch_info = checkpoint['best_epoch_info']\n",
    "current_lr = checkpoint['current_lr']\n",
    "current_patience = checkpoint['current_parience']       \n",
    "metadata = checkpoint['metadata']\n",
    "info = checkpoint['best_epoch_info']\n",
    "history = checkpoint['history']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for info in history:\n",
    "    print(info['train_acc'])\n",
    "    print(info)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_col(history, column):\n",
    "\n",
    "    train_metric = [info[f'train_{column}'] for info in history]\n",
    "    val_metric = [info[f'val_{column}'] for info in history]\n",
    "    print(train_metric)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8, 6))\n",
    "    epochs = range(1, len(train_metric) + 1)\n",
    "\n",
    "    # Plot training and validation losses\n",
    "    ax.plot(epochs, train_metric, label=f\"Training {column}\", marker=\"o\", linestyle=\"-\", color=\"blue\")\n",
    "    ax.plot(epochs, val_metric, label=f\"Validation {column}\", marker=\"o\", linestyle=\"-\", color=\"red\")\n",
    "\n",
    "    # Add labels, title, and legend\n",
    "    ax.set_title(f\"Training and Validation {column}\")\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(column)\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "columns = ['loss', 'acc', 'micro', 'macro', 'weighted', 'f1_C0', 'f1_C1', 'f1_C2', 'f1_C3', 'f1_C4', 'CE', 'dice']    \n",
    "#for c in columns:\n",
    "#    plot_col(history, c)\n",
    "\n",
    "def get_best(history):\n",
    "    lowest_loss = np.inf\n",
    "    info_best = {}\n",
    "    for info in history:\n",
    "        if info['val_loss'] <= lowest_loss:\n",
    "            lowest_loss = info['val_loss']\n",
    "            info_best = info\n",
    "    return info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['loss', 'acc', 'micro', 'macro', 'weighted', 'f1_C0', 'f1_C1', 'f1_C2', 'f1_C3', 'f1_C4', 'CE', 'dice']   \n",
    "for c in columns:\n",
    "    view.plot_metrics(history, c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ponderado: nao tao bom pra classe 4, melhor nas 1, 2 e 3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles = ['032027']#, '032026'] \n",
    "num_subtiles = 6\n",
    "classes_mode = 'type'\n",
    "training_batch_size = 16\n",
    "model_types = 'unets'\n",
    "weighted = True\n",
    "\n",
    "if classes_mode == 'type':\n",
    "    num_classes = 5\n",
    "elif classes_mode == 'density':\n",
    "    num_classes = 4\n",
    "elif classes_mode == 'binary':\n",
    "    num_classes = 2\n",
    "elif classes_mode == 'all':\n",
    "    num_classes = 9\n",
    "\n",
    "\n",
    "working_dir = os.path.abspath('..')\n",
    "models_paths = os.listdir(os.path.join(working_dir, 'models'))\n",
    "models_paths = [f for f in models_paths if f.endswith('.pth')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_files, val_files, test_files = data.train_val_test_stratify(tiles, \n",
    "                                                                  num_subtiles,\n",
    "                                                                    train_size = 0.6, \n",
    "                                                                    val_size = 0.2, \n",
    "                                                                    stratify_by = classes_mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_types == 'unets':\n",
    "    model_param_grid = {\n",
    "        #model params:\n",
    "        'model' : [#f'UNetSmall-256-{classes_mode}',\n",
    "                #f'UNet-256-{classes_mode}', #ok\n",
    "                #f'UNet-64-{classes_mode}', #ok\n",
    "                #f'UNetResNet34-224-{classes_mode}', #ok\n",
    "                #f'UNetEfficientNetB0-224-{classes_mode}', \n",
    "                f'UNetConvNext-224-{classes_mode}',\n",
    "                ],\n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile = '032026'\n",
    "\n",
    "folder = os.path.join(working_dir,f\"data/processed/S2-16D_V2_{tile}/{num_subtiles}x{num_subtiles}_subtiles\")\n",
    "files = os.listdir(folder)\n",
    "files = [os.path.join(folder, f) for f in files if f.endswith('.tif')]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = patch_size-32\n",
    "for tile_id in ['032026', '025037', '032027']:\n",
    "    # --------------- opening files -----------------\n",
    "    folder = os.path.join(working_dir,f\"data/processed/S2-16D_V2_{tile_id}/{num_subtiles}x{num_subtiles}_subtiles\")\n",
    "    files = os.listdir(folder)\n",
    "    files = [os.path.join(folder, f) for f in files if f.endswith('.tif')]\n",
    "    # --------------- creating a dataloader -----------------\n",
    "    test_dataset = data.SubtileDataset(files, \n",
    "                                    num_subtiles = 6,\n",
    "                                    classes_mode=classes_mode,\n",
    "                                    patch_size=patch_size, \n",
    "                                    stride=stride, #//2, \n",
    "                                    dynamic_sampling = False,\n",
    "                                    data_augmentation = False, # testando \n",
    "                                    return_imgidx = True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=training_batch_size, shuffle=False)\n",
    "    #for image, mask, x, y, f in test_loader:\n",
    "    #    print(f'{x},{y}',end='|')\n",
    "    tile = post.ReconstructTile(patch_size = patch_size, stride = stride)\n",
    "\n",
    "    ### -------------- TESTING -------------------\n",
    "    import time\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "    run_time = time.time()\n",
    "    runner = train.EpochRunner('test', model, test_loader, criterion=criterion, num_classes=num_classes, \n",
    "                                optimizer=None, simulated_batch_size = test_loader.batch_size, device = device)  \n",
    "    for image, label, logits, pred, x, y, f, in runner.run_generator(show_pred = 1):\n",
    "        tile.add_batch(x, y, f, logits, pred, label, image)\n",
    "    tile.set_pred()      \n",
    "    loss, CE, dice, report, acc, cm = runner.get_metrics()\n",
    "    run_time = time.time()-run_time\n",
    "    peak_train_memory = f\"{torch.cuda.max_memory_allocated() / 1024 ** 2:.2f} MB\"\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    \n",
    "    print(f'Test Loss: {loss}, {CE}, {dice}')\n",
    "    print(f'Test Accuracy: {acc}')\n",
    "    print(f'Test confusion matrix:')\n",
    "    view.plot_confusion_matrix(cm)\n",
    "    print(report)\n",
    "    \n",
    "    #### ----------------- Contruct tile\n",
    "    \n",
    "    \n",
    "\n",
    "    r = [0, 10560, 0, 10560]\n",
    "    #r = [5000, 7000, 1000, 3000]\n",
    "\n",
    "    plt.figure(figsize=(50, 50))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(tile.labels[r[0]:r[1], r[2]:r[3]])\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(tile.preds[r[0]:r[1], r[2]:r[3]])\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(range(4, 16-4)))\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(tile.count[1700-256:1800+256, 1700-256:1800+256])\n",
    "print(np.unique(tile.count))\n",
    "print(10560//6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1504+256)\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(prob[4,230:280, 230:280])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile.post_process()\n",
    "\n",
    "plt.figure(figsize=(50, 50))\n",
    "plt.subplot(2,2,1)\n",
    "plt.imshow(tile.cleaned[3000:7000,0:4000])\n",
    "plt.subplot(2,2,2)\n",
    "plt.imshow(tile.crf[3000:7000,0:4000])\n",
    "plt.subplot(2,2,3)\n",
    "plt.imshow(tile.cleaned_crf[3000:7000,0:4000])\n",
    "plt.subplot(2,2,4)\n",
    "plt.imshow(tile.vi_completion[3000:7000,0:4000])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.morphology import remove_small_objects\n",
    "\n",
    "def remove_small(final_mask, min_size = 10):\n",
    "    final_mask = remove_small_objects(final_mask, min_size=min_size)\n",
    "    return final_mask\n",
    "\n",
    "a = remove_small(tile.crf, min_size = 25)\n",
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,10))\n",
    "t = tile.tile\n",
    "t=t-np.min(t)\n",
    "t/=np.max(t)\n",
    "\n",
    "r = [3000, 7000, 0, 4000]\n",
    "#plt.imshow(t, cmap='gray')\n",
    "plt.figure(figsize=(50, 50))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(tile.labels[r[0]:r[1],r[2]:r[3]])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(tile.preds[r[0]:r[1],r[2]:r[3]])\n",
    "#plt.subplot(1,3,3)\n",
    "#plt.imshow(tile_032026.cleaned_preds[3000:7000,0:4000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view.plt_tile(tile.labels[3000:7000,0:4000], tile.preds[3000:7000,0:4000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map = {\n",
    "        0: ('Reds', 0.0, 'Fundo'),\n",
    "        1: ('Blues', 0.8, 'Loteamento Vazio'),\n",
    "        2: ('Greens', 0.8, 'Outros Equipamentos'),\n",
    "        3: ('Reds', 0.8, 'Vazio Intraurbano'),\n",
    "        4: ('Oranges', 0.8, 'Área Urbanizada')\n",
    "    }\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 8))\n",
    "view.plot_masked_image(tile.labels[3000:7000,0:4000], label_map, image=None, title=\"Mask Overlay Only\", ax=axs[0])\n",
    "view.plot_masked_image(tile.preds[3000:7000,0:4000], label_map, image=None, title=\"Mask Overlay Only\", ax=axs[1])\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(16, 16))\n",
    "view.plot_masked_image(tile.cleaned_preds[3000:7000,0:4000], label_map, image=None, title=\"Cleaned\", ax=axs[0])\n",
    "view.plot_masked_image(tile.crf[3000:7000,0:4000], label_map, image=None, title=\"CRF\", ax=axs[1])\n",
    "view.plot_masked_image(tile.cleaned_crf[3000:7000,0:4000], label_map, image=None, title=\"CRF+Clean\", ax=axs[2])\n",
    "view.plot_masked_image(tile.vi_completion[3000:7000,0:4000], label_map, image=None, title=\"+completion\", ax=axs[3])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_config_file = os.path.join(working_dir, 'config', 'pca_weights.npy')\n",
    "print(tile.image.shape)\n",
    "pca_img = torch.Tensor(data.apply_pca_weights(tile.image, pca_config_file))\n",
    "pca_img = pca_img.permute(1, 2, 0).detach().cpu().numpy()\n",
    "#pca_img -= np.min(pca_img)\n",
    "#pca_img /= np.max(pca_img)\n",
    "\n",
    "label_map = {\n",
    "        0: ('Reds', 0.1, 'Fundo'),\n",
    "        1: ('Blues', 0.8, 'Loteamento Vazio'),\n",
    "        2: ('Greens', 0.8, 'Outros Equipamentos'),\n",
    "        3: ('Purples', 0.8, 'Vazio Intraurbano'),\n",
    "        4: ('Oranges', 0.8, 'Área Urbanizada')\n",
    "    }\n",
    "fig, axs = plt.subplots(1, 2, figsize=(16, 8))\n",
    "view.plot_masked_image(tile.labels[3000:7000,0:4000], label_map, image=pca_img[3000:7000,0:4000], title=\"Mask Overlay Only\", ax=axs[0])\n",
    "view.plot_masked_image(tile.preds[3000:7000,0:4000], label_map, image=pca_img[3000:7000,0:4000], title=\"Mask Overlay Only\", ax=axs[1])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(pca_img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.figure(figsize=(10,10))\n",
    "#plt.imshow(tile_032026.logits)\n",
    "tile_032026.preds[:200,:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(tile_032026.logits_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (256, 256+32)\n",
    "y = (2256, 2256+32)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(tile_032026.logits[x[0]:x[1],y[0]:y[1]])\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(tile_032026.logits_0[x[0]:x[1],y[0]:y[1]])\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(tile_032026.labels[x[0]:x[1],y[0]:y[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "sigmoid(tile_032026.logits_0[:10,:10])\n",
    "plt.imshow(sigmoid(tile_032026.logits[x[0]:x[1],y[0]:y[1]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Define the folder containing the CSV files\n",
    "working_dir = os.path.abspath('..')\n",
    "folder_path = os.path.join(working_dir, 'experimental_results')\n",
    "\n",
    "# Initialize an empty list to store the rows\n",
    "rows_list = []\n",
    "\n",
    "# Iterate over all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.csv'):\n",
    "        # Construct the full file path\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Filter rows where the 'Status' column contains 'current best val loss.'\n",
    "        filtered_df = df[df['Status'].str.contains('current best val loss.', na=False)]\n",
    "        \n",
    "        # If there are any matching rows, take the last one\n",
    "        if not filtered_df.empty:\n",
    "            last_row = filtered_df.iloc[-1]\n",
    "            rows_list.append(last_row)\n",
    "\n",
    "# Combine all the rows into a single DataFrame\n",
    "combined_df = pd.DataFrame(rows_list)\n",
    "\n",
    "# Reset the index of the combined DataFrame\n",
    "combined_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df['Model path'][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[combined_df['Model']=='UNetSmall-256-type-diceW']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iter=100\n",
    "start_lr=1e-6\n",
    "end_lr=1e-3\n",
    "lr_mult = (end_lr / start_lr) ** (1/num_iter)\n",
    "lr_mult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_lr_finder import LRFinder\n",
    "\n",
    "# Dummy dataset\n",
    "class DummyDataset(Dataset):\n",
    "    def __len__(self):\n",
    "        return 100\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.randn(3, 32, 32)  # Input: 3x32x32 image\n",
    "        y = torch.randint(0, 10, (1,)).item()  # Target: class label\n",
    "        return x, y  # Must return (input, target)\n",
    "\n",
    "# Dummy model\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(3*32*32, 10)\n",
    ").cuda()\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(DummyDataset(), batch_size=8)\n",
    "\n",
    "# Test LRFinder\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-7)\n",
    "lr_finder = LRFinder(model, optimizer, torch.nn.CrossEntropyLoss())\n",
    "lr_finder.range_test(train_loader, end_lr=0.1, num_iter=100)  # Should work!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in train_loader:\n",
    "    print(x, y)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "class DistLayer(torch.nn.Linear):\n",
    "    def __init__(self, in_features, out_features, n=1., eps=1e-6, bias=False):\n",
    "        super(DistLayer, self).__init__(in_features, out_features, bias=bias)\n",
    "        self.n = n\n",
    "        self.eps = eps\n",
    "        \n",
    "    def forward(self, x, scale=False):\n",
    "        # x: (B, N)\n",
    "        # w: (V, N)\n",
    "        # dist_sq: (B, V)\n",
    "        n_embd = x.size(-1,)\n",
    "        w = self.weight\n",
    "        #w.data *= 0.\n",
    "        wx = torch.einsum('bn,vn->bv', x, w) # (B, V)\n",
    "        ww = torch.norm(w, dim=-1)**2 # (V,)\n",
    "        xx = torch.norm(x, dim=-1)**2 # (B,)\n",
    "\n",
    "        dist_sq = ww[None,:] + xx[:,None] - 2 * wx + self.eps\n",
    "        dist_sq = dist_sq / torch.min(dist_sq, dim=-1, keepdim = True)[0]\n",
    "        return (dist_sq)**(-self.n)\n",
    "\n",
    "inputs = torch.tensor([[0.,1.], [0., -1,], [-1., 0.], [1., 0.], [0., 0.]])\n",
    "labels = torch.tensor([0,1,2,3,4], dtype=torch.long)\n",
    "\n",
    "distlayer = DistLayer(2,5)\n",
    "\n",
    "lr = 1e-2\n",
    "n_steps = 10000\n",
    "optimizer = torch.optim.Adam(distlayer.parameters(), lr = lr)\n",
    "ws = []\n",
    "w_l2s = []\n",
    "ls = []\n",
    "\n",
    "for i in range(n_steps):\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    prob = distlayer(inputs)\n",
    "    prob = prob/torch.sum(prob, dim=1, keepdim=True)\n",
    "    logits = torch.log(prob)\n",
    "    loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    ws.append(copy.deepcopy(distlayer.weight.detach().numpy()))\n",
    "    w_l2s.append(np.linalg.norm(distlayer.weight.detach().numpy()))\n",
    "    ls.append(loss.item())\n",
    "    \n",
    "ls_h = np.array(ls)\n",
    "w_l2s_h = np.array(w_l2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs.shape\n",
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distlayer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
