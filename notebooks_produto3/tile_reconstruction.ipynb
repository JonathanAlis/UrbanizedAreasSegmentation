{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montagem dos tiles e pos-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def print_gpu_memory(prefix=\"\"):\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / (1024 ** 2)\n",
    "        reserved = torch.cuda.memory_reserved() / (1024 ** 2)\n",
    "        print(f\"{prefix} Memory Allocated: {allocated:.2f} MB\")\n",
    "        print(f\"{prefix} Memory Reserved: {reserved:.2f} MB\")\n",
    "    else:\n",
    "        print(\"CUDA is not available.\")\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache() \n",
    "\n",
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import src.data.preprocess_data as data\n",
    "import src.training.train_model as train\n",
    "import src.data.view as view\n",
    "import src.models.unets as unets\n",
    "import src.models.hrnets as hrnets\n",
    "import src.training.post_processing as post\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "channels_dict = {}\n",
    "channels_dict[12] = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B09', 'B11', 'B12', 'B8A']\n",
    "channels_dict[10] = ['B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B11', 'B12', 'B8A']\n",
    "channels_dict[8] = ['B02', 'B03', 'B04', 'B05', 'B06', 'B08', 'B11', 'B12']\n",
    "channels_dict[6] = ['B02', 'B03', 'B04', 'B06', 'B08', 'B11']\n",
    "channels_dict[4] = ['B02', 'B03', 'B04','B08']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subtiles = 6\n",
    "num_classes = 4\n",
    "\n",
    "working_dir = os.path.abspath('..')\n",
    "\n",
    "classes_mode = '4types'\n",
    "if classes_mode == 'type':\n",
    "    num_classes = 5\n",
    "elif classes_mode == 'density':\n",
    "    num_classes = 4\n",
    "elif classes_mode == '4types':\n",
    "    num_classes = 4\n",
    "elif classes_mode == 'all':\n",
    "    num_classes = 9\n",
    "else:\n",
    "    num_classes = 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### exemplo:\n",
    "\n",
    "Primeiramente, vamos montar um tile de exemplo, a partir das predições de um modelo fixo\n",
    "A seguir, definimos o modelo e parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_id = '025037'\n",
    "ch = 4\n",
    "model_name = f'UNetSmall-256-4types-DS-CEW-{ch}ch-4tt'\n",
    "patch_size = 256\n",
    "BS = 16 # batch size\n",
    "\n",
    "# define qual o dado de entrada para inferencia \n",
    "folder = os.path.join(working_dir,f\"data/processed/S2-16D_V2_{tile_id}/{num_subtiles}x{num_subtiles}_subtiles\")\n",
    "files = os.listdir(folder)\n",
    "files = [os.path.join(folder, f) for f in files if f.endswith('.tif')]\n",
    "\n",
    "# carrega o modelo\n",
    "print('Model name:', model_name)\n",
    "if model_name.startswith('UNetSmall-'):\n",
    "    model = unets.UNetSmall(in_channels=ch, out_channels=num_classes).to(device) \n",
    "\n",
    "ckp_file = os.path.join(working_dir, 'models', model_name+'.pth')\n",
    "checkpoint = torch.load(ckp_file, weights_only=False)\n",
    "model.load_state_dict(checkpoint['best_model_state_dict'])\n",
    "\n",
    "                \n",
    "#parametros da montagem\n",
    "stride = patch_size-32\n",
    "edge_removal = 8\n",
    "\n",
    "# --------------- opening files -----------------\n",
    "folder = os.path.join(working_dir,f\"data/processed/S2-16D_V2_{tile_id}/{num_subtiles}x{num_subtiles}_subtiles/q_12ch\")\n",
    "files = os.listdir(folder)\n",
    "files = [os.path.join(folder, f) for f in files if f.endswith('.tif')]\n",
    "\n",
    "# --------------- creating a dataloader -----------------\n",
    "indices = [i for i, value in enumerate(channels_dict[ch]) if value in channels_dict[12]]\n",
    "\n",
    "tile_dataset = data.SubtileDataset(files, \n",
    "                                num_subtiles = 6,\n",
    "                                classes_mode=classes_mode,\n",
    "                                patch_size=patch_size, \n",
    "                                stride=stride, #//2, \n",
    "                                dynamic_sampling = False,\n",
    "                                data_augmentation = False,\n",
    "                                channels_subset= indices,\n",
    "                                return_imgidx = True)\n",
    "dataloader = DataLoader(tile_dataset, batch_size=BS, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montando o tile\n",
    "\n",
    "Criamos o objeto que guarda as reconstruções.\n",
    "\n",
    "Em seguida, faz a inferência usando o modelo, (em runner.run_generator) e adiciona os batches no reconstrutor (tile.add_batch)\n",
    "\n",
    "Em seguida, faz a predição geral do tile (em tile.set_pred()).\n",
    "\n",
    "Por fim, faz o pos processamento (em tile.post_process_tile) e salva os resultados (tile.save_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# aqui cria o objeto de reconstrucao do tile\n",
    "tile = post.ReconstructTile(patch_size = patch_size, stride = stride, edge_removal=edge_removal, \n",
    "                            num_classes=num_classes, num_channels=ch, tile_id=tile_id)\n",
    "\n",
    "\n",
    "import time\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "run_time = time.time()\n",
    "\n",
    "print('Inferindo...')        \n",
    "runner = train.EpochRunner('test', model, dataloader, num_classes=num_classes, \n",
    "                            simulated_batch_size = dataloader.batch_size, device = device)  \n",
    "for image, label, logits, pred, x, y, f, in runner.run_generator(show_pred = 0):\n",
    "    tile.add_batch(x, y, f, logits, pred, label, image)\n",
    "print('Montando...')\n",
    "tile.set_pred()   \n",
    "#print('Pos processamento...')\n",
    "#labels, pred_patch, clean_pred, clean_noholes, clean_noholes_2, noholes, noholes2, rules = tile.post_process(0,0)\n",
    "\n",
    "#returned = tile.post_process(x, y)\n",
    "print('Salvando...')        \n",
    "tile.save_pred(folder_name = model_name)\n",
    "    \n",
    "loss, CE, dice, report, acc, cm = runner.get_metrics()\n",
    "run_time = time.time()-run_time\n",
    "peak_train_memory = f\"{torch.cuda.max_memory_allocated() / 1024 ** 2:.2f} MB\"\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Replace with actual variable\n",
    "\n",
    "\n",
    "print(f'Test Loss: {loss}, {CE}, {dice}')\n",
    "print(f'Test Accuracy: {acc}')\n",
    "#print(f'Test confusion matrix:')\n",
    "view.plot_single_confusion_matrix(cm)\n",
    "print(report)\n",
    "\n",
    "#### ----------------- Contruct tile\n",
    "\n",
    "\n",
    "\n",
    "r = [0, 10560, 0, 10560]\n",
    "#r = [5000, 7000, 1000, 3000]\n",
    "\n",
    "plt.figure(figsize=(50, 50))\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(tile.labels[r[0]:r[1], r[2]:r[3]])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(tile.preds[r[0]:r[1], r[2]:r[3]])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizando a limpeza das predições\n",
    "\n",
    "podemos aplicar a limpeza para cada patch do tile que desejamos.\n",
    "\n",
    "Vamos aplicar num pedaço do tile (iniciando em 0,0, e indo até 1760)\n",
    "\n",
    "Pode alterar esses valores para ver outras posicoes do tile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_pos, y_pos = 0, 1000\n",
    "size = 1760\n",
    "labels, pred_patch, crf, morph, crf_morph, sieve = tile.post_process_patch(x_pos, y_pos, size)\n",
    "titles = [\"Referência\", \"Predição do modelo\", \"CRF\", \"Limpeza morfológica\"]\n",
    "rgb = tile.rgb_image[x_pos:x_pos+size, y_pos:y_pos+size,:]\n",
    "save_to = os.path.join(working_dir, 'figs', 'post_clean_1.png')\n",
    "view.plot_mask_list([labels, pred_patch, crf, morph], background = rgb, titles = titles, num_classes = 4, save_to=save_to)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fazendo a limpeza do tile inteiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tile.post_process_tile(folder_name = model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quanta memória usou?\n",
    "\n",
    "Aqui calculamos o tanto de memória utilizado no processo. Some-ase o valor em memória de todos os atributos do objeto reconstrutor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calcular_tamanho_atributos(objeto):\n",
    "    \"\"\"Calcula o tamanho de cada atributo de um objeto.\"\"\"\n",
    "    tamanho_total = sys.getsizeof(objeto)\n",
    "    print(f\"Tamanho do objeto: {tamanho_total} bytes\")\n",
    "\n",
    "    for atributo in dir(objeto):\n",
    "        if not atributo.startswith(\"__\"):  # Ignora atributos especiais\n",
    "            try:\n",
    "                valor_atributo = getattr(objeto, atributo)\n",
    "                tamanho_atributo = sys.getsizeof(valor_atributo)\n",
    "                print(f\"  Atributo '{atributo}': {tamanho_atributo/1_048_576:.3f} Megabytes\")\n",
    "                tamanho_total += tamanho_atributo\n",
    "            except AttributeError:\n",
    "                pass  # Ignora atributos que não podem ser acessados\n",
    "\n",
    "    print(f\"Tamanho total (aproximado): {tamanho_total/1_048_576:.3f} Megabytes\")\n",
    "\n",
    "print(calcular_tamanho_atributos(tile))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Montando todos os tiles utilizados\n",
    "\n",
    "Para um modelo fixo UNetSmall-256-4types-DS-CEW, 4 canais, tanto o treinamento original como o finetune.\n",
    "\n",
    "Faz a montagem das predições de todos os 12 tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tiles = {\n",
    "              'Manaus': '016009',\n",
    "              'Porto Alegre': '025037',\n",
    "              'Belo Horizonte': '032027',\n",
    "              'Salvador': '038019',      \n",
    "\n",
    "              'Boa Vista': '015002',  \n",
    "              'Campo Grande': '021027',\n",
    "              'Macapá': '025005',\n",
    "              'Curitiba': '027032',\n",
    "              'Brasília': '028022',                      \n",
    "              'Rio de Janeiro': '033029',\n",
    "              'Teresina': '034011',\n",
    "              'Petrolina': '036016',\n",
    "\n",
    "              }\n",
    "\n",
    "in_channels = [4]#, 8]\n",
    "finetune = [False, True]#, True]\n",
    "\n",
    "models = [#{'model_name': 'UNet-256-4types-DS-CEW', 'patch_size':256, 'batch_size':16, 'note': ''},\n",
    "          {'model_name': 'UNetSmall-256-4types-DS-CEW', 'patch_size':256, 'batch_size':16, 'note': ''},]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tile_id in list(all_tiles.values()):#['032027']:#, '025037', '032027']:\n",
    "    \n",
    "    folder = os.path.join(working_dir,f\"data/processed/S2-16D_V2_{tile_id}/{num_subtiles}x{num_subtiles}_subtiles\")\n",
    "    files = os.listdir(folder)\n",
    "    files = [os.path.join(folder, f) for f in files if f.endswith('.tif')]\n",
    "    for model_dict in models:\n",
    "        for ch in in_channels:\n",
    "            for ft in finetune:\n",
    "                model_name = model_dict['model_name']\n",
    "                model_name += f'-{ch}ch-4tt'#UNet-256-4types-DS-CE-6ch-4tt\n",
    "                ckp_file = os.path.join(working_dir, 'models', model_name+'.pth')\n",
    "                if ft:\n",
    "                    model_name += f'-finetuned-8ft'#UNet-256-4types-DS-CE-6ch-4tt\n",
    "                    ckp_file = os.path.join(working_dir, 'models', 'finetuned', model_name+'.pth')\n",
    "                    \n",
    "                print('Model name:', model_name)\n",
    "                if model_name.startswith('UNetSmall-'):\n",
    "                    model = unets.UNetSmall(in_channels=ch, out_channels=num_classes).to(device) \n",
    "                elif model_name.startswith('UNet-'):\n",
    "                    model = unets.UNet(in_channels=ch, out_channels=num_classes).to(device) \n",
    "                elif model_name.startswith('UNetResNet34-'):\n",
    "                    model = unets.UNetResNet34(in_channels=ch, out_channels=num_classes).to(device) \n",
    "                elif model_name.startswith('UNetEfficientNetB0-'):\n",
    "                    model = unets.UNetEfficientNetB0(in_channels=ch, out_channels=num_classes).to(device) \n",
    "                elif model_name.startswith('UNetConvNext-'):\n",
    "                    model = unets.UNetConvNext(in_channels=ch, out_channels=num_classes).to(device) \n",
    "                elif model_name.startswith('HRNetW18'):\n",
    "                    model = hrnets.HRNetSegmentation(in_channels= ch, num_classes=num_classes, backbone=\"hrnet_w18_small\", pretrained=True,).to(device)\n",
    "                elif model_name.startswith('HRNetW32'):\n",
    "                    model = hrnets.HRNetSegmentation(in_channels= ch, num_classes=num_classes, backbone=\"hrnet_w32\", pretrained=True,).to(device)\n",
    "                elif model_name.startswith('HRNetW48'):\n",
    "                    model = hrnets.HRNetSegmentation(in_channels= ch, num_classes=num_classes, backbone=\"hrnet_w48\", pretrained=True,).to(device)\n",
    "                else:\n",
    "                    print('Nao existe esse modelo')\n",
    "                    continue\n",
    "                checkpoint = torch.load(ckp_file, weights_only=False)\n",
    "                model.load_state_dict(checkpoint['best_model_state_dict'])\n",
    "\n",
    "                patch_size = model_dict['patch_size']\n",
    "                stride = patch_size-32\n",
    "                edge_removal = 8\n",
    "                if patch_size == 64:\n",
    "                    stride = patch_size-16\n",
    "                    edge_removal = 4\n",
    "\n",
    "                # --------------- opening files -----------------\n",
    "                folder = os.path.join(working_dir,f\"data/processed/S2-16D_V2_{tile_id}/{num_subtiles}x{num_subtiles}_subtiles/q_12ch\")\n",
    "                files = os.listdir(folder)\n",
    "                files = [os.path.join(folder, f) for f in files if f.endswith('.tif')]\n",
    "                print(files)\n",
    "                if len(files)==0:\n",
    "                    continue\n",
    "                # --------------- creating a dataloader -----------------\n",
    "                indices = [i for i, value in enumerate(channels_dict[ch]) if value in channels_dict[12]]\n",
    "                \n",
    "                tile_dataset = data.SubtileDataset(files, \n",
    "                                                num_subtiles = 6,\n",
    "                                                classes_mode=classes_mode,\n",
    "                                                patch_size=patch_size, \n",
    "                                                stride=stride, #//2, \n",
    "                                                dynamic_sampling = False,\n",
    "                                                data_augmentation = False,\n",
    "                                                channels_subset= indices,\n",
    "                                                return_imgidx = True)\n",
    "                dataloader = DataLoader(tile_dataset, batch_size=model_dict['batch_size'], shuffle=False)\n",
    "                \n",
    "                tile = post.ReconstructTile(patch_size = patch_size, stride = stride, edge_removal=edge_removal, \n",
    "                                            num_classes=num_classes, num_channels=ch, tile_id=tile_id)\n",
    "\n",
    "\n",
    "                import time\n",
    "                torch.cuda.reset_peak_memory_stats()\n",
    "                run_time = time.time()\n",
    "\n",
    "                print('Inferindo...')        \n",
    "                runner = train.EpochRunner('test', model, dataloader, num_classes=num_classes, \n",
    "                                            simulated_batch_size = dataloader.batch_size, device = device)  \n",
    "                for image, label, logits, pred, x, y, f, in runner.run_generator(show_pred = 0):\n",
    "                    tile.add_batch(x, y, f, logits, pred, label, image)\n",
    "                    #print(np.unique(tile.preds))\n",
    "                print('Montando...')\n",
    "                tile.set_pred()   \n",
    "\n",
    "                #print('Pos processamento...')\n",
    "                #labels, pred_patch, clean_pred, clean_noholes, clean_noholes_2, noholes, noholes2, rules = tile.post_process(0,0)\n",
    "\n",
    "                #returned = tile.post_process(x, y)\n",
    "                print('Salvando...')        \n",
    "                tile.save_pred(tile_id, folder_name = model_name)\n",
    "                    \n",
    "                loss, CE, dice, report, acc, cm = runner.get_metrics()\n",
    "                run_time = time.time()-run_time\n",
    "                peak_train_memory = f\"{torch.cuda.max_memory_allocated() / 1024 ** 2:.2f} MB\"\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                # Replace with actual variable\n",
    "                \n",
    "                \n",
    "                print(f'Test Loss: {loss}, {CE}, {dice}')\n",
    "                print(f'Test Accuracy: {acc}')\n",
    "                #print(f'Test confusion matrix:')\n",
    "                view.plot_single_confusion_matrix(cm)\n",
    "                print(report)\n",
    "                \n",
    "                #### ----------------- Contruct tile\n",
    "                \n",
    "                \n",
    "\n",
    "                r = [0, 10560, 0, 10560]\n",
    "                #r = [5000, 7000, 1000, 3000]\n",
    "\n",
    "                plt.figure(figsize=(50, 50))\n",
    "                plt.subplot(1,2,1)\n",
    "                plt.imshow(tile.labels[r[0]:r[1], r[2]:r[3]])\n",
    "                plt.subplot(1,2,2)\n",
    "                plt.imshow(tile.preds[r[0]:r[1], r[2]:r[3]])\n",
    "                plt.show()\n",
    "                \n",
    "                # pos ptrocessando:                \n",
    "                tile.post_process_tile()\n",
    "                tile.save_cleaning(folder_name = model_name)\n",
    "\n",
    "                del tile\n",
    "                import gc\n",
    "                gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
