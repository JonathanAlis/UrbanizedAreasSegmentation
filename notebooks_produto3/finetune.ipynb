{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_gpu_memory(prefix=\"\"):\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / (1024 ** 2)\n",
    "        reserved = torch.cuda.memory_reserved() / (1024 ** 2)\n",
    "        print(f\"{prefix} Memory Allocated: {allocated:.2f} MB\")\n",
    "        print(f\"{prefix} Memory Reserved: {reserved:.2f} MB\")\n",
    "    else:\n",
    "        print(\"CUDA is not available.\")\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache() \n",
    "\n",
    "print_gpu_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "import src.models.unets as unets\n",
    "import src.data.preprocess_data as data\n",
    "import src.training.train_model as train\n",
    "import src.models.hrnets as hrnets\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### É feito no conjunto de 8 tiles, nao usados no treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_finetune = {\n",
    "              'Boa Vista': '015002',  \n",
    "              'Campo Grande': '021027',\n",
    "              'Macapá': '025005',\n",
    "              'Curitiba': '027032',\n",
    "              'Brasília': '028022',                      \n",
    "              'Rio de Janeiro': '033029',\n",
    "              'Teresina': '034011',\n",
    "              'Petrolina': '036016',\n",
    "              }\n",
    "\n",
    "tiles = tiles_finetune.values() \n",
    "num_subtiles = 6\n",
    "classes_mode = '4types'\n",
    "model_types = 'unets'\n",
    "\n",
    "if model_types=='unets':\n",
    "    training_batch_size = 16\n",
    "\n",
    "#model_types = 'unets'\n",
    "\n",
    "if classes_mode == 'type':\n",
    "    num_classes = 5\n",
    "elif classes_mode == '4types':\n",
    "    num_classes = 4\n",
    "elif classes_mode == 'density':\n",
    "    num_classes = 4\n",
    "elif classes_mode == 'binary':\n",
    "    num_classes = 2\n",
    "elif classes_mode == 'all':\n",
    "    num_classes = 9\n",
    "\n",
    "\n",
    "\n",
    "channels_dict = {}\n",
    "channels_dict[12] = ['B01', 'B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B09', 'B11', 'B12', 'B8A']\n",
    "channels_dict[10] = ['B02', 'B03', 'B04', 'B05', 'B06', 'B07', 'B08', 'B11', 'B12', 'B8A']\n",
    "channels_dict[8] = ['B02', 'B03', 'B04', 'B05', 'B06', 'B08', 'B11', 'B12']\n",
    "channels_dict[6] = ['B02', 'B03', 'B04', 'B06', 'B08', 'B11']\n",
    "channels_dict[4] = ['B02', 'B03', 'B04','B08']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_models_batch = {f'UNetSmall-64-{classes_mode}' : 16, #512,\n",
    "                     f'UNetSmall-256-{classes_mode}' : 32,\n",
    "                     f'UNet-64-{classes_mode}': 256,\n",
    "                     f'UNet-256-{classes_mode}': 16,\n",
    "                     f'UNetResNet34-224-{classes_mode}': 128, #ok\n",
    "                     f'UNetEfficientNetB0-224-{classes_mode}': 64, \n",
    "                     f'UNetConvNext-224-{classes_mode}': 32,\n",
    "                     f'HRNetW18-512-{classes_mode}': 4,\n",
    "                     f'HRNetW32-512-{classes_mode}': 4,\n",
    "                     f'HRNetW48-512-{classes_mode}': 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_types == 'unets':\n",
    "    model_param_grid = {\n",
    "\n",
    "        #model params:\n",
    "        \n",
    "        'model' : [#f'UNetSmall-64-{classes_mode}',\n",
    "                   f'UNetSmall-256-{classes_mode}',\n",
    "               #f'UNet-256-{classes_mode}', #ok\n",
    "                #f'UNet-64-{classes_mode}', #ok\n",
    "                #f'UNetResNet34-224-{classes_mode}', #ok\n",
    "                #f'UNetEfficientNetB0-224-{classes_mode}', \n",
    "                #f'UNetConvNext-224-{classes_mode}',\n",
    "                ],\n",
    "            \n",
    "        #training params\n",
    "            # loss\n",
    "        'loss': ['CE'], #-dice', 'dice'],#,'groups'],#, 'dice', 'CE-dice'],\n",
    "        'weighted_loss': [True], #Wegted loss, +CE: bom recall pra 2, 3, 4, ruim resto\n",
    "        'dist_loss':[False],\n",
    "        'crf': [False],#[0.0001],    \n",
    "        'epochs' : [15],\n",
    "        'patience' : [3],\n",
    "        'batch_size' : [training_batch_size],\n",
    "        'dynamic_sampling' : [True],\n",
    "        'data_augmentation' : [True],\n",
    "        'num_channels': [8, 4]\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_files, val_files, test_files = data.train_val_test_stratify(tiles, \n",
    "                                                                  num_subtiles,\n",
    "                                                                    train_size = 0.6, \n",
    "                                                                    val_size = 0.2, \n",
    "                                                                    stratify_by = classes_mode,\n",
    "                                                                    subfolder='q_12ch')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleção de modelos a serem finetunados\n",
    "\n",
    "Busca por todos treinados, que sejam UNetSmall, DS-CEW, de 4 ou 8 canais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.path.abspath('..')\n",
    "checkpoints = os.listdir(os.path.join(working_dir, 'models'))\n",
    "checkpoints = [ckp for ckp in checkpoints if ckp.endswith('tt.pth')]\n",
    "checkpoints = [ckp for ckp in checkpoints if ckp.startswith('UNetSmall')]\n",
    "checkpoints = [ckp for ckp in checkpoints if 'DS-CEW' in ckp]\n",
    "#checkpoints = [ckp for ckp in checkpoints if 'CE' in ckp]\n",
    "checkpoints = [ckp for ckp in checkpoints if ('-4ch-' in ckp or '-8ch-' in ckp)]\n",
    "\n",
    "print('Checkpoints salvos:')\n",
    "print(checkpoints)\n",
    "\n",
    "finetune_epochs = 15\n",
    "checkpoints = [os.path.join(working_dir, 'models',ckp) for ckp in checkpoints]\n",
    "#checkpoints = [ckp for ckp in checkpoints if 'UNetSmall-256-4types-DS-CEW-4ch-4tt.pth' in ckp]\n",
    "checkpoints\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop de finetune:\n",
    "\n",
    "Para cada modelo, carrega o modelo, obtém o checkpoint final, aplica o modelo no conjunto de treino, calcula as métricas, cria um novo dataset com os patches com menos de 50% de macro F-1, e inicia o re-treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "for checkpoint_path in checkpoints:\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        checkpoint = torch.load(checkpoint_path, weights_only=False)\n",
    "        metadata = checkpoint['metadata']\n",
    "        \n",
    "        model_name = metadata['model_name'] #: 'UNetSmall-256-4types-DS-CE-10ch-4tt'\n",
    "        print(\"Modelo: \", model_name)\n",
    "        print(metadata)\n",
    "        csv = metadata['file_path']\n",
    "        df = pd.read_csv(csv)\n",
    "        #display(df)\n",
    "        model_name_splitted = model_name.split('-') # ['UNetSmall', '256', '4types', 'DS', 'CE', '12ch', '4tt']\n",
    "        model_params = {}\n",
    "        model_params['crf'] = '-crf-' in model_name\n",
    "        model_params['dist_loss'] = '-dist-' in model_name\n",
    "        model_params['dynamic_sampling'] = '-DS-' in model_name\n",
    "        model_params['data_augmentation'] = '-DA-' in model_name\n",
    "        model_params['model_class'] = model_name_splitted[0]\n",
    "        model_params['patch_size'] = int(model_name_splitted[1])\n",
    "        model_params['loss'] = model_name_splitted[-3].removesuffix('W')\n",
    "        model_params['weighted_loss'] = model_name_splitted[-3].endswith('W')\n",
    "        model_params['num_channels'] = int(model_name_splitted[-2].removesuffix('ch'))\n",
    "        print(model_params)\n",
    "\n",
    "        \n",
    "            \n",
    "        \n",
    "        patch_size = int(model_name.split('-')[1])\n",
    "        print('--------------------')\n",
    "        print('Finetuning', model_name)\n",
    "\n",
    "        finetuned_csv = os.path.join(working_dir, 'experimental_results', 'finetune', model_name+'-8ft.csv')\n",
    "        finetuned_model = os.path.join(working_dir, 'models', 'finetune', model_name+'-finetuned-8ft.pth')\n",
    "        \n",
    "        if os.path.exists(finetuned_csv) and os.path.exists(finetuned_model):\n",
    "            with open(finetuned_csv, 'r', newline='', encoding='utf-8') as csvfile:\n",
    "                reader = csv.reader(csvfile)\n",
    "                line_count = sum(1 for row in reader)\n",
    "                print(f'Tuned for {line_count} epochs')            \n",
    "            if line_count > finetune_epochs:\n",
    "                print('Finetune already completed.')\n",
    "                continue\n",
    "        print(model_params)\n",
    "        model_class = model_params['model_class']\n",
    "        patch_size = model_params['patch_size']\n",
    "\n",
    "\n",
    "        # define quais indices\n",
    "        num_ch = model_params['num_channels']\n",
    "        indices = [i for i, value in enumerate(channels_dict[num_ch]) if value in channels_dict[12]]\n",
    "\n",
    "        yaml_filename = data.yaml_filename(num_subtiles, tiles, classes_mode)\n",
    "\n",
    "        train_dataset = data.SubtileDataset(yaml_filename, \n",
    "                                        set = 'train_files',\n",
    "                                        patch_size=patch_size, \n",
    "                                        stride=patch_size,\n",
    "                                        classes_mode=classes_mode,\n",
    "                                        channels_subset= indices,\n",
    "                                        dynamic_sampling = False, #model_params['dynamic_sampling'] ,\n",
    "                                        data_augmentation = False,# model_params['data_augmentation'], # testando \n",
    "                                        return_imgidx = True,\n",
    "                                        #set = 'finetune_train'\n",
    "\n",
    "                                        )\n",
    "        \n",
    "        val_dataset = data.SubtileDataset(yaml_filename, \n",
    "                                        set = 'val_files',\n",
    "                                        patch_size=patch_size, \n",
    "                                        stride=patch_size,\n",
    "                                        classes_mode=classes_mode,\n",
    "                                        channels_subset = indices,\n",
    "                                        dynamic_sampling = False,\n",
    "                                        data_augmentation = False,\n",
    "                                        #set = 'finetune_val'\n",
    "                                        )\n",
    "        \n",
    "        test_dataset = data.SubtileDataset(yaml_filename, \n",
    "                                        set = 'test_files',\n",
    "                                        patch_size=patch_size, \n",
    "                                        stride=patch_size,\n",
    "                                        classes_mode=classes_mode,\n",
    "                                        channels_subset = indices,\n",
    "                                        dynamic_sampling = False,\n",
    "                                        data_augmentation = False,\n",
    "                                        #set = 'finetune_test'\n",
    "                                        )\n",
    "\n",
    "\n",
    "        \n",
    "        if model_params['weighted_loss']:                   \n",
    "            class_counts, per_image = train_dataset.count_classes()\n",
    "            class_weights = 1.0 / class_counts  # Inverse of class frequencies\n",
    "            class_weights = class_weights / torch.sum(class_weights)  # Normalize\n",
    "        else:    \n",
    "            class_weights = None\n",
    "\n",
    "        dynamic_sampling = train_dataset.dynamic_sampling\n",
    "        data_augmentation = train_dataset.data_augmentation   \n",
    "\n",
    "        train_loader = DataLoader(train_dataset, batch_size=training_batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=training_batch_size, shuffle=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=training_batch_size, shuffle=False)\n",
    "\n",
    "        if model_name.startswith('UNetSmall-'):\n",
    "            model = unets.UNetSmall(in_channels=num_ch, out_channels=num_classes, crf=model_params['crf'], use_dist = model_params['dist_loss']).to(device) \n",
    "        elif model_name.startswith('UNet-'):\n",
    "            model = unets.UNet(in_channels=num_ch, out_channels=num_classes, crf=model_params['crf']).to(device) \n",
    "        elif model_name.startswith('UNetResNet34-'):\n",
    "            model = unets.UNetResNet34(in_channels=num_ch, out_channels=num_classes, crf=model_params['crf']).to(device) \n",
    "        elif model_name.startswith('UNetEfficientNetB0-'):\n",
    "            model = unets.UNetEfficientNetB0(in_channels=num_ch, out_channels=num_classes, crf=model_params['crf']).to(device) \n",
    "        elif model_name.startswith('UNetConvNext-'):\n",
    "            model = unets.UNetConvNext (in_channels=num_ch, out_channels=num_classes, crf=model_params['crf']).to(device) \n",
    "        elif model_name.startswith('HRNetW18'):\n",
    "            model = hrnets.HRNetSegmentation(in_channels= num_ch, num_classes=num_classes, backbone=\"hrnet_w18_small\", pretrained=True,).to(device)\n",
    "        elif model_name.startswith('HRNetW32'):\n",
    "            model = hrnets.HRNetSegmentation(in_channels= num_ch, num_classes=num_classes, backbone=\"hrnet_w32\", pretrained=True,).to(device)\n",
    "        elif model_name.startswith('HRNetW48'):\n",
    "            model = hrnets.HRNetSegmentation(in_channels= num_ch, num_classes=num_classes, backbone=\"hrnet_w48\", pretrained=True,).to(device)\n",
    "        else:\n",
    "            print(f'Modelo {model_name} não está no param grid. Pulando...')\n",
    "            continue\n",
    "\n",
    "\n",
    "        ### Inferencia:\n",
    "        working_dir = os.path.abspath('..')\n",
    "        checkpoint_path_ = os.path.join(working_dir, 'models', checkpoint_path)\n",
    "        if os.path.exists(checkpoint_path_):\n",
    "            checkpoint = torch.load(checkpoint_path_, weights_only=False)\n",
    "            metadata = checkpoint['metadata']\n",
    "            #print(checkpoint_path)\n",
    "            #print(checkpoint)\n",
    "            model.load_state_dict(checkpoint['best_model_state_dict'])\n",
    "        else:\n",
    "            raise ValueError(f\"Erro na leitura do modelo {checkpoint_path_}.\")\n",
    "        criterion = train.CombinedLoss(loss_mode = model_params['loss'], weights = None, return_all_losses=True)\n",
    "\n",
    "        runner = train.EpochRunner('test', model, train_loader, criterion, num_classes=num_classes, \n",
    "                                    optimizer=None, simulated_batch_size = train_loader.batch_size, device = device)\n",
    "\n",
    "        patches = []   \n",
    "        ious = [] \n",
    "        threshold = 0.8\n",
    "        counter = 0\n",
    "        for image, label, logits, pred, x, y, f, in runner.run_generator(show_pred = 1):\n",
    "            x, y, f, logits, pred, label, image\n",
    "            #for bi in range(pred.shape[0]):\n",
    "            IOU, mean_IOU, macro_IOU = train.compute_iou_per_sample(pred,label,num_classes=num_classes)\n",
    "            counter+=pred.shape[0]\n",
    "            for i in range(pred.shape[0]):\n",
    "                #TODO: ver se o label tem classe 1 e 2. \n",
    "                \n",
    "                pct_loteamento = (label == 1).sum().item()/label.numel()\n",
    "                pct_equipamentos = (label == 2).sum().item()/label.numel()\n",
    "                pct_AU = (label != 0).sum().item()/label.numel()\n",
    "                \n",
    "                if macro_IOU[i]<=threshold and pct_loteamento+pct_equipamentos >= 0.01:\n",
    "                    print(macro_IOU[i])\n",
    "                    print(IOU[i])\n",
    "                    print(pct_loteamento, pct_equipamentos)\n",
    "\n",
    "                    idx_dict = {'file':f[i], \n",
    "                                'x':x[i].item(), \n",
    "                                'y':y[i].item(), \n",
    "                                'transform' : 0,\n",
    "                                'step_shift' : 0\n",
    "                                }               \n",
    "                    patches.append(idx_dict)\n",
    "                    ious.append((IOU, mean_IOU, macro_IOU, pct_loteamento, pct_equipamentos))\n",
    "            #if len(patches)>0:\n",
    "            #    break\n",
    "        print('TOTAL SELECTED PATCHES:', len(patches))\n",
    "        print('TOTAL PATCHES:', counter)\n",
    "        print('PERCENTUAL SELECTED PATCHES:', 100*len(patches)/counter)\n",
    "        print(patches[0])\n",
    "        print(ious[0])\n",
    "\n",
    "        if 1:\n",
    "            loss, CE, dice, report, acc, cm = runner.get_metrics()\n",
    "            peak_val_memory = f\"{torch.cuda.max_memory_allocated() / 1024 ** 2:.2f} MB\"\n",
    "            torch.cuda.empty_cache()\n",
    "            print('_____________________________________')\n",
    "            print(checkpoint_path)\n",
    "            print(f'Loss: {loss}, {CE}, {dice}')\n",
    "            print(f'Accuracy: {acc}')\n",
    "            print(f'confusion matrix:')\n",
    "                    \n",
    "\n",
    "        selection_train_dataset = data.SubtileDataset(patches, \n",
    "                                        set = 'train_files',\n",
    "                                        patch_size=patch_size, \n",
    "                                        stride=patch_size,\n",
    "                                        classes_mode=classes_mode,\n",
    "                                        channels_subset= indices,\n",
    "                                        dynamic_sampling = True, #model_params['dynamic_sampling'] ,\n",
    "                                        data_augmentation = True, #model_params['data_augmentation'], # testando \n",
    "                                        return_imgidx = True,\n",
    "                                        #set = 'finetune_selection_train'\n",
    "                                        )\n",
    "        selection_train_loader = DataLoader(selection_train_dataset, batch_size=training_batch_size, shuffle=True)\n",
    "        print('Tamanho do novo dataset para o finetune: ', len(selection_train_loader))\n",
    "        print(selection_train_dataset.count_classes())\n",
    "\n",
    "        pixel_count, subtile_count = selection_train_dataset.count_classes()\n",
    "        weights = [torch.sum(pixel_count)/c for c in pixel_count]\n",
    "        weights = [w/sum(weights) for w in weights]\n",
    "        \n",
    "        finetune_params = {'epochs': finetune_epochs,\n",
    "                           'loss_mode': 'CE',\n",
    "                           'patience': 3,\n",
    "                           'weights': weights, # [0.1, 1, 1, 0.5],\n",
    "                           'save_to': model_name+f'-finetuned-{len(tiles)}ft.pth',\n",
    "                           'maximum_lr':0.1 \n",
    "                           }\n",
    "        print('Treinando...')\n",
    "        print('pesos:', weights)\n",
    "        train.train_model(model, \n",
    "                        selection_train_loader, \n",
    "                        val_loader, \n",
    "                        epochs=finetune_params['epochs'], \n",
    "                        loss_mode = finetune_params['loss_mode'],\n",
    "                        device = device,\n",
    "                        num_classes = num_classes, \n",
    "                        simulated_batch_size = training_batch_size, #model_params['batch_size'] ,\n",
    "                        patience = finetune_params['patience'],\n",
    "                        weights = finetune_params['weights'],\n",
    "                        show_batches = 1, \n",
    "                        save_to = finetune_params['save_to'],\n",
    "                        save_subfolder= 'finetuned',\n",
    "                        maximum_lr=finetune_params['maximum_lr']) #o padrao é 0.1, entao esse é 10x menos.\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
